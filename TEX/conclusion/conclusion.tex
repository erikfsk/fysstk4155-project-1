We have seen how the different models behave. The time was almosst irrelevant for choosing
OLS, Ridge or Lasso. The k-folding technique reduced the time and also preserved the R2 score and MSE.
The Lasso might not be the best fit to the real data, but it has the simplest model.
It has 8 coefficient, compared to 21 for Ridge and OLS. If the module was meant to predict
new values, Lasso would save you 13 FLOPs per prediction, while only droping slightly in R2
score and MSE accuracy. A pretty good deal if many predictions are needed with the model. An other conclusion
that might be as interesting is that we should keep using the Scikit package. Our code...
Well, it did not perform as well as we would have liked.
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
\\
